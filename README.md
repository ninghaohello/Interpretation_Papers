Another github repo that shows different interpretation methods on image classification: (https://github.com/albermax/innvestigate) <br />

# Interpretation for NLP
* [Towards a Deep and Unified Understanding of Deep Neural Models in NLP (ICML19)](http://proceedings.mlr.press/v97/guan19a/guan19a.pdf) <br />
* [Interpretable Adversarial Perturbation in Input Embedding Space for Text (IJCAI18)](https://www.ijcai.org/Proceedings/2018/0601.pdf) <br />
* [Attention is not Explanation (NAACL19)](https://www.aclweb.org/anthology/N19-1357/) <br />
* [Attention is not not Explanation (EMNLP19)](https://www.aclweb.org/anthology/D19-1002) <br />
* [Is Attention Interpretable? (ACL19)](https://arxiv.org/pdf/1906.03731.pdf) <br />

# Interpretation & Adversary
* [Interpretation of Neural Networks is Fragile (AAAI19)](https://arxiv.org/pdf/1710.10547.pdf) <br />
* [Interpreting Adversarially Trained Convolutional Neural Networks (ICML19)](https://arxiv.org/pdf/1905.09797.pdf) <br />

# Interpretation & Human Knowledge
* [Learning Credible Deep Neural Networks with Rationale Regularization (ICDM19)](https://arxiv.org/pdf/1908.05601.pdf) <br />
